# ViT-Small/16 + CIFAR-100 Configuration (Quick Test)
model_name: "vit_small_patch16_224"
dataset: "cifar100"
data_dir: "./data"
image_size: 224
batch_size: 32
num_workers: 0  # Avoid shared memory issues

# Training parameters (Quick test)
epochs: 5  # Just 5 epochs for quick test
learning_rate: 0.001
weight_decay: 0.05
optimizer: "adamw"
scheduler: "cosine"
warmup_epochs: 1

# LoRA parameters
lora_rank: 8
lora_alpha: 16
lora_dropout: 0.1
target_modules: ["qkv", "proj"]  # ViT attention modules

# Evaluation parameters
eval_frequency: 1
save_best_model: true

# Performance benchmarking
warmup_iterations: 3
benchmark_iterations: 10
plot_dir: "plots"

# Training comparison settings
comparison_modes: ["baseline", "lora"]
save_checkpoints: true
checkpoint_dir: "./checkpoints"
results_dir: "./results/vit_small_cifar100_quick_test"
