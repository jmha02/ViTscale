# ViTscale: ViT Performance Benchmarking with LoRA

A comprehensive benchmarking suite for analyzing Vision Transformer (ViT) performance with LoRA (Low-Rank Adaptation) optimizations. This project provides detailed analysis of both **inference** and **training** performance characteristics.

## ğŸš€ Features

### ğŸ” **Dual Performance Analysis**
- **Inference Benchmarking**: Measures forward pass speed, memory usage, and FLOPs
- **Training Benchmarking**: Measures full training step (forward + backward + optimizer) performance
- **Comparative Analysis**: Side-by-side comparison of baseline vs LoRA models

### âš¡ **Key Metrics**
- **Speed**: Inference time, training time per batch, throughput (FPS/samples per sec)
- **Memory**: Peak GPU memory usage during inference and training
- **Efficiency**: Parameter count, trainable parameter percentage, computational load (FLOPs)
- **Scalability**: LoRA rank impact analysis (ranks 4, 8, 16, 32, 64)

### ğŸ“Š **Comprehensive Reporting**
- Interactive HTML reports with detailed analysis
- Visualization plots and charts
- Performance trade-off analysis
- Recommendations for optimal configurations

## ğŸ› ï¸ Installation

```bash
# Create conda environment
conda env create -f environment.yml
conda activate vitscale

# Verify CUDA setup (recommended)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

## ğŸ“ˆ Usage

### 1. **Inference Performance Benchmarking**
```bash
# Run inference benchmark (forward pass only)
python run_inference_benchmark.py

# Analyze inference results
python run_inference_analysis.py
```
**Measures**: Forward pass speed, memory consumption, FLOPs computation

### 2. **Training Performance Benchmarking**
```bash
# Run training benchmark (forward + backward + optimizer)
python run_training_benchmark.py

# Analyze training results  
python run_training_analysis.py
```
**Measures**: Full training step performance, gradient computation time, memory efficiency

### 3. **Basic Training (Optional)**
```bash
# Train baseline ViT
python main.py --config configs/default.yaml --mode baseline

# Train ViT with LoRA
python main.py --config configs/default.yaml --mode lora
```

## ğŸ“ Project Structure

```
ViTscale/
â”œâ”€â”€ ğŸ”§ Core Scripts
â”‚   â”œâ”€â”€ run_inference_benchmark.py    # Inference performance benchmarking
â”‚   â”œâ”€â”€ run_training_benchmark.py     # Training performance benchmarking  
â”‚   â”œâ”€â”€ run_inference_analysis.py     # Inference results analysis
â”‚   â”œâ”€â”€ run_training_analysis.py      # Training results analysis
â”‚   â””â”€â”€ main.py                       # Basic training script
â”‚
â”œâ”€â”€ ğŸ—ï¸ Framework
â”‚   â”œâ”€â”€ benchmarks/                   # Core benchmark implementations
â”‚   â”‚   â”œâ”€â”€ inference.py              # Inference benchmark logic
â”‚   â”‚   â””â”€â”€ training.py               # Training benchmark logic
â”‚   â”œâ”€â”€ analysis/                     # Analysis implementations
â”‚   â”‚   â”œâ”€â”€ inference.py              # Inference analysis logic
â”‚   â”‚   â””â”€â”€ training.py               # Training analysis logic
â”‚   â”œâ”€â”€ models/                       # ViT and LoRA model implementations
â”‚   â”œâ”€â”€ utils/                        # Performance measurement utilities
â”‚   â””â”€â”€ configs/                      # Configuration files
â”‚
â”œâ”€â”€ ğŸ“Š Results
â”‚   â”œâ”€â”€ plots/                        # Benchmark results and visualizations
â”‚   â””â”€â”€ analysis/                     # Detailed analysis reports
â”‚       â””â”€â”€ results/                  # Generated analysis outputs
â”‚           â”œâ”€â”€ inference/            # Inference-specific analysis
â”‚           â””â”€â”€ training/             # Training-specific analysis
â”‚
â””â”€â”€ ğŸ“‹ Setup
    â”œâ”€â”€ environment.yml               # Conda environment setup
    â””â”€â”€ README.md                    # This file
```

## âš™ï¸ Configuration

Edit `configs/default.yaml` to customize:

```yaml
# Model and dataset
model_name: "vit_base_patch16_224"
dataset: "cifar10"
batch_size: 32

# LoRA parameters  
lora_rank: 8
lora_alpha: 16
lora_dropout: 0.1
target_modules: ["qkv", "proj"]  # ViT attention modules

# Performance settings
warmup_iterations: 5
benchmark_iterations: 100
```
